<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
	<!-- <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"> -->
	<!-- <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'"> -->
	<!-- <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'"> -->
	<!-- <link rel="stylesheet" href="/css/wowchemy.042e26407c9e383d96a1f26d6787c686.css" /> -->
	<!-- <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" > -->
	<!-- <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled> -->
	<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css" integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin="anonymous" media="print" onload="this.media='all'"> -->
	<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">
	<!-- <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/6.5.1/css/font-awesome.css"> -->
	<!-- <link rel="apple-touch-icon" sizes="57x57" href="icon/apple-icon-57x57.png">
	<link rel="apple-touch-icon" sizes="60x60" href="icon/apple-icon-60x60.png">
	<link rel="apple-touch-icon" sizes="72x72" href="icon/apple-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="76x76" href="icon/apple-icon-76x76.png">
	<link rel="apple-touch-icon" sizes="114x114" href="icon/apple-icon-114x114.png">
	<link rel="apple-touch-icon" sizes="120x120" href="icon/apple-icon-120x120.png">
	<link rel="apple-touch-icon" sizes="144x144" href="icon/apple-icon-144x144.png">
	<link rel="apple-touch-icon" sizes="152x152" href="icon/apple-icon-152x152.png">
	<link rel="apple-touch-icon" sizes="180x180" href="icon/apple-icon-180x180.png">
	<link rel="icon" type="image/png" sizes="192x192" href="icon/android-icon-192x192.png">
	<link rel="icon" type="image/png" sizes="32x32" href="icon/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="icon/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="icon/favicon-16x16.png"> -->
	<link rel="icon" type="image/png" sizes="32x32" href="assets/icon/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="180x180" href="assets/icon/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="16x16" href="assets/icon/favicon-16x16.png">
	<link rel="icon" type="image/png" sizes="192x192" href="assets/icon/android-chrome-192x192.png">
	<link rel="icon" type="image/png" sizes="512x512" href="assets/icon/android-chrome-512x512.png">
	<link rel="manifest" href="icon/manifest.json">
	<meta name="msapplication-TileColor" content="#ffffff">
	<meta name="msapplication-TileImage" content="assets/icon/favicon-32x32.pngg">
	<meta name="theme-color" content="#ffffff">
	<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests" />
	<title>Huanxuan Liao | Homepage</title>
	<style type="text/css">
		h1 {
			text-align: center;
			font-size: 50px;
		}
	</style>
	<script async defer src="https://buttons.github.io/buttons.js"></script>
</head>

<body>
	<!--     <h1>Seeking for a Master Degree...</h1>   -->
	<br>
</body>

</html>

<!DOCTYPE html>
<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<style media="screen" type="text/css">
		/* 		<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" /> */
		body {
			border: 0pt none;
			font-family: inherit;
			font-size: 100%;
			font-style: inherit;
			font-weight: inherit;
			margin: 0pt;
			outline-color: invert;
			outline-style: none;
			outline-width: 0pt;
			padding: 0pt;
			vertical-align: baseline;
		}

		body {
			position: relative;
			margin: 3em auto 2em auto;
			width: 1080px;
			font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
			font-size: 14px;
			background: #fdfdfd;
		}
	</style>
	<!-- <style>
			body {
			  color: #333;
			  background-color: #eee;
			}
			@media (prefers-color-scheme: dark) {
			  body {
				color: #ccc;
				background-color: #1f1f1f;
			  }
			}
		</style> -->
	<style>
		/* 普通模式下颜色 */
		:root {
			--color-bg: #ffffff;
			--color-ch: #30303a;
			--color-btn: #f0f0fa;
			--color-link: #1565c0;
		}

		/* 黑暗模式下颜色 */
		:root[theme='dark'] {
			--color-bg: #272935;
			--color-ch: #e3e3f1;
			--color-btn: #30303a;
			--color-link: #a2bfd9;
		}

		:root * {
			/* 过渡动画效果 */
			transition: background-color 0.3s, color 0.3s;
		}

		body {
			position: relative;
			background-color: var(--color-bg);
			/* transition: 0.3s; */
		}

		button {
			position: absolute;
			top: -1%;
			right: -5%;
			height: 48px;
			width: 48px;
			border-radius: 50%;
			border: none;
			outline: none;
			background-color: var(--color-btn);
			display: flex;
			align-items: center;
			justify-content: center;
			/* transition: 0.3s; */
		}

		a:link {
			text-decoration: underline;
			TEXT-DECORATION: none;
		}

		a:visited {
			text-align: left;
			text-decoration: underline;
			TEXT-DECORATION: none;
		}

		a:hover {
			color: rgb(201, 74, 10);
			text-decoration: underline;
			TEXT-DECORATION: none;
		}

		a:active {
			color: #de123b;
			text-decoration: none;
		}

		p,
		b,
		td,
		h2,
		i,
		a,
		ul,
		ul li,
		pre {
			color: var(--color-ch);
			font-family: Arial, Times, serif;
			/* transition: 0.3s; */
		}

		.myself {
			color: #0000ff
		}

		.cropped {
			width: 60px;
			height: 60px;
			overflow: hidden;
		}

		.cropped img {
			margin: 0px 0px 0px 0px;
		}

		pre {
			font-size: 15px;
		}

		ul li {
			font-size: 20px;
		}

		i,
		a {
			color: var(--color-link);
			font-family: Arial, Times, serif;
			/* transition: 0.3s; */
		}

		button>svg {
			height: 36px;
			width: 36px;
			fill: var(--color-ch);
			stroke: none;
		}

		button>svg:nth-child(2) {
			display: none;
		}

		@media (prefers-color-scheme: dark) {

			/* 普通模式下颜色 */
			:root {
				--color-bg: #272935;
				--color-ch: #e3e3f1;
				--color-btn: #30303a;
				--color-link: #a2bfd9;
			}

			/* 黑暗模式下颜色 */
			:root[theme='dark'] {
				--color-bg: #ffffff;
				--color-ch: #30303a;
				--color-btn: #f0f0fa;
				--color-link: #1573df;
			}
		}
	</style>

	<script>
		var _hmt = _hmt || [];
		(function () {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?1ec4ad5c61857459aa78d5ee7ddee28d";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
		})();
	</script>
	<script src="http://cdn.staticfile.org/jquery/2.0.0/jquery.min.js">
	</script>
	<!-- <script>$(document).ready(function () {
            $(".bu").click(function () {
                if ($("pre").css("display") != "none") {
                    $("pre").css("display", "none");
                } else {
                    $("pre").css("display", "block");
                }
            });
        });</script> -->
	<script>
		$(function () {
			$(".bu").click(function () {
				if ($('.bib' + $(this).attr("id")).css("display") != "none") {
					$('.bib' + $(this).attr("id")).css("display", "none");
				} else {
					if ($('.ab' + $(this).attr("id")).css("display") != "none") {
						$('.ab' + $(this).attr("id")).css("display", "none");
					}
					$('.bib' + $(this).attr("id")).css("display", "block");
				}
			})
			$(".au").click(function () {
				if ($('.ab' + $(this).attr("id")).css("display") != "none") {
					$('.ab' + $(this).attr("id")).css("display", "none");
				} else {
					if ($('.bib' + $(this).attr("id")).css("display") != "none") {
						$('.bib' + $(this).attr("id")).css("display", "none");
					}
					$('.ab' + $(this).attr("id")).css("display", "block");
				}
			})
		})
	</script>
</head>

<body>
	<button>
		<svg viewBox="0 0 24 24">
			<path
				d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z">
			</path>
		</svg>
		<svg viewBox="0 0 24 24">
			<path
				d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z">
			</path>
		</svg>
	</button>
	<script>
		const root = document.documentElement;
		const button = document.querySelector('button');
		const svgs = document.querySelectorAll('button>svg');
		const text = document.querySelector('p');

		button.onclick = () => {
			if (!root.hasAttribute('theme')) { // 检查当前主题
				root.setAttribute('theme', 'dark'); // 向根节点插入theme属性，值为dark
				// 这样页面中颜色就会匹配 :root[theme='dark'] { ... } 这一套
				svgs[0].style.display = 'none';
				svgs[1].style.display = 'block';

			} else {
				root.removeAttribute('theme'); // 移除根节点theme属性
				svgs[1].style.display = 'none';
				svgs[0].style.display = 'block';

			}
		};
	</script>
	<table align="center">
		<tr>
			<td align="center"><img border=0 style="border-radius:8px;" height="218" width="198" src="img/profile.jpg">
			</td>
			<td align="center">&nbsp</td>
			<td align="center">&nbsp</td>
			<td align="center">
			<td align="center">
				<h2>
					<font face="Arial" size=+2>Huanxuan Liao</font>&emsp;
					<b>
						<font face="楷体" size=+2>廖桓萱</font>
					</b>
				</h2>
				<p>
					<font size=+1>
						<font size=+2 face="Arial">NLPer @ NLPR, CASIA</font><br />
						<font size=+2>&#x1F30F</font> <b><a href="http://www.ia.cas.cn/" target="_self">Institute of
								Automation, Chinese Academy of Sciences</a></b>
						<font face="Arial">, Beijing, China</font>
					</font>
				</p>
				<p style="margin-top: -0.4cm; margin-bottom: -0.02cm;">
					<font size=+1>
						<font size=+3>&#x2709</font> <i><b><a href="mailto:liaohuanxuan2023@ia.ac.cn">
									<font size=+1 face="Arial">liaohuanxuan2023@ia.ac.cn</font></b></i></a>
					</font>
				</p>

				<div style="display: inline-block; margin-top:0%">
					<a href="assets/CV.pdf" target="_self">
						<font size=7><i class="fa fa-user-circle" aria-hidden="true"></i></font>
					</a>
				</div>
				&emsp;
				<!-- Google Scholar -->
				<div style="display: inline-block; margin-right:0.0cm"">
					<a href=" https://scholar.google.com.hk/citations?user=sRcWOKUAAAAJ&hl=zh-CN" target="_self">
					<img src="img/google-scholar-icon.png" alt="Google Scholar" title="Google Scholar" width="40px" />

					</a>
				</div>
				&emsp;
				<!-- Semantic Scholar -->
				<div class="cropped" style="display: inline-block;">
					<a href=" https://www.semanticscholar.org/author/Huanxuan-Liao/2232817310" target="_self">
						<img src="img/semantic-scholar-icon.png" style="position:relative;top: 20px;"
							alt="Semantic Scholar" title="Semantic Scholar" width="220px" />
					</a>
				</div>
				<!-- Mail -->
				<div style="display: inline-block; margin-bottom:0.0cm">
					<a href="mailto:huanxuanliao@gmail.com" target="_self">
						<font size=7><i class="fa fa-envelope" aria-hidden="true"></i>
						</font>
					</a>
				</div>
				&emsp;
				<!-- GitHub -->
				<div style="display: inline-block; margin-bottom:0.0cm">
					<a href="https://github.com/Xnhyacinth" target="_self">
						<font size=7><i class="fa fa-github" aria-hidden="true"></i>
						</font>
					</a>
				</div>
				<!-- <div style="display: inline-block; margin-right:0.0cm">
					<a href="https://github.com/Xnhyacinth" target="_self">
						<img src="https://upload.wikimedia.org/wikipedia/commons/c/c2/GitHub_Invertocat_Logo.svg"
							alt="Github" title="Github" width="48px" />
					</a>
				</div> -->
				&emsp;
				<div style="display: inline-block; margin-top:0%">
					<a href="https://twitter.com/xn_hyacinth" target="_self">
						<font size=7><i aria-hidden="true" class="fa fa-twitter"></i></font>
					</a>
				</div>
			</td>
			</td>
		</tr>
	</table>
	<br />
	<div>
		<h2>
			<font face="Arial" size=+3.5>Biography</font>
		</h2>
		<hr />
		<p>
			<font size="4.5" face="Arial">
				I’m the first year M.S student at the Institute of Automation, Chinese Academy of Sciences (CASIA),
				supervised by A.P. <a href="http://www.nlpr.ia.ac.cn/cip/shizhuhe/">Shizhu He </a>.
				Before that, I have received B.Eng. from <a href="https://www.ncepu.edu.cn/">North China
					Electric Power University (NCEPU)</a> in 2023, under the supervision of
				A.P. Min Shi and A.P. Yun Ju.

				<br><br>My research interests lie at <b>Large Language Model</b>, <b>Long Context Modeling</b> and
				<b>Natural Language Reasoning</b>.
			</font>
		</p>

		<div class="app">
			<div style="float:left;width:50%;">
				<h2><b>
						<font face="Arial" size=+2>Interests</font>
					</b></h2>
				<p>
					<font size="4">
						&emsp;&emsp;<i class="fa fa-file-text-o"></i>
						Question Answering
						<br><br>
						&emsp;&emsp;<i class="fa fa-file-text-o"></i>
						Large Language Model
						<br><br>
						&emsp;&emsp;<i class="fa fa-file-text-o"></i>
						Natural Language Reasoning
						<br><br>
						&emsp;&emsp;<i class="fa fa-file-text-o"></i>
						<a href="https://github.com/Xnhyacinth/Long_Text_Modeling_Papers" target="_self">Long Context
							Modeling & Length Extrapolation</a>
					</font>
				</p>
			</div>
			<div style="float:left;width:50%;">
				<h2>
					<font face="Arial" size=+2>Education</font>
				</h2>
				<p>
					<font size="4">
						&emsp;&emsp;<i class="fa fa-graduation-cap"></i>
						M.S in Computer Science, 2023-now
						<br>
						<font size="3">&emsp;&emsp;&emsp;&emsp;</font>
						<font size="4" color="a9a9ae">Institute of Automation, Chinese Academy of Sciences</font>
						<br><br>
						&emsp;&emsp;<i class="fa fa-graduation-cap"></i>
						B.Eng. in Intelligence Science and Technology, 2019-2023
						<br>
						<font size="3">&emsp;&emsp;&emsp;&emsp;</font>
						<font size="4" color="a9a9ae">North China Electric Power University, China</font>
					</font>
				<p>&emsp;&emsp;</p>
				</p>
			</div>

		</div>
		<br>
	</div>
	<!-- <h2><font face="Arial" size=+3.5>Research Interests</font></h2>
	<hr/>
	<p>
		<font size="4">
			&emsp;&emsp;<i class="fa fa-file-text-o"></i>
			Natural Language Processing
			<br><br>
			&emsp;&emsp;<i class="fa fa-file-text-o"></i>
			Reasoning
			<br><br>
			&emsp;&emsp;<i class="fa fa-file-text-o"></i>
			<a href="https://github.com/Xnhyacinth/Long_Text_Modeling_Papers" target="_self">Long Context Modeling & Length Extrapolation</a>
		</font>
	</p>
	<br> -->
	<br />
	&nbsp;&nbsp;&nbsp;&nbsp;
	<div>
		<h2>
			<font face="Arial" size=+3.5>Publications</font> &nbsp;<a
				href="https://scholar.google.com.hk/citations?user=sRcWOKUAAAAJ&hl=zh-CN" target="_self"><img
					src="img/google-scholar.png" alt="Google Scholar" width="90px" /></a>
		</h2>
		<hr />
		<br />

		<font size="5"><b>2024</b></font>

		<ul>
			<li>
				<font size="4">
					<b><a href="https://arxiv.org/abs/2403.15268" ">Imagination Augmented Generation: Learning to Imagine Richer Context
						for Question Answering over Large Language Models</a></b>
				</font>
				<font size=" 3">
							&nbsp;&nbsp;
							<br />
							<b class="myself">Huanxuan Liao</b>
							<font face="Arial">, Shizhu He, Yao Xu, Yuanzhe Zhang, Kang Liu, Shengping Liu, Jun Zhao
							</font>
							&nbsp;&nbsp; <br> <i><b>Preprint</b></i>, 2024.
				</font>
				<br>
				<div class="bu" id="3" style="display: inline-block; margin-top:0%">
					<font size="6"><i class="fa fa-info" aria-hidden="true"></i></font>&nbsp;<img alt="Static Badge"
						src="https://img.shields.io/badge/Bib-5cb85c" style="width: 35px;">
				</div>
				&nbsp;
				<div class="au" id="3" style="display: inline-block; margin-top:0%">
					<font size="6"><i class="fa fa-flag" aria-hidden="true"></i></font>&nbsp;<img alt="Static Badge"
						src="https://img.shields.io/badge/Abstract-f9adad" style="width: 70px;">
				</div>
				&nbsp;

				<a href="https://github.com/Xnhyacinth/IAG">
					<font size="6"><i class="fa fa-github-alt" aria-hidden="true"></i></font>&nbsp;<img
						alt="Static Badge" src="https://img.shields.io/badge/Code-d9534f" style="width: 50px;">
				</a>
				&nbsp;
				<a class="tag" href="cites/IAG.bib" target="_self">
					<font size="6"><i class="fa fa-download" aria-hidden="true"></i></font>&nbsp;<img id="2"
						alt="Static Badge" src="https://img.shields.io/badge/Cite-edd7be" style="width: 43px;">
				</a>
				<div class="bib3" style="display:none; width: 95%; border:1px solid #e8dada">
					<pre>
@misc{liao2024imagination,
	title={Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models}, 
	author={Huanxuan Liao and Shizhu He and Yao Xu and Yuanzhe Zhang and Kang Liu and Shengping Liu and Jun Zhao},
	year={2024},
	eprint={2403.15268},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}
		</pre>
				</div>
				<div class="ab3" style="display:none; width: 95%; border:1px solid #e8dada">
					<pre>
  Retrieval-Augmented-Generation and Gener-ation-Augmented-Generation have been proposed to enhance the knowledge required for question
  answering over Large Language Models (LLMs). However, the former depends on external resources, and both require incorporating the explicit
  documents into the context, which results in longer contexts that lead to more resource consumption. Recent works indicate that LLMs have
  modeled rich knowledge, albeit not effectively triggered or activated. Inspired by this, we propose a novel knowledge-augmented framework, Imag-
  ination-Augmented-Generation (IAG), which simulates the human capacity to compensate for knowledge deficits while answering questions solely
  through imagination, without relying on external resources. Guided by IAG, we propose an imagine richer context method for question answering
  (IMcQA), which obtains richer context through the following two modules: explicit imagination by generating a short dummy document with long con-
  text compress and implicit imagination with HyperNetwork for generating adapter weights. Experimental results on three datasets demonstrate that
  IMcQA exhibits significant advantages in both open-domain and closed-book settings, as well as in both in-distribution performance and out-of-
  distribution generalizations. Our code will be available at this https URL.
		</pre>
				</div>
			</li>
			<br />
		</ul>

		<font size="5"><b>2023</b></font>

		<ul>
			<li>
				<font size="4">
					<b><a href="https://arxiv.org/abs/2308.10252" ">LMTuner: An
							user-friendly and
							highly-integrable Training Framework for fine-tuning
							Large Language Models</a></b>
				</font>
				<font size=" 3">
							&nbsp;&nbsp;
							<br />
							<font face="Arial">Yixuan Weng, Zhiqi Wang, </font><b class="myself">Huanxuan Liao</b>
							<font face="Arial">, Shizhu He, Shengping Liu, Kang Liu, Jun Zhao</font>
							&nbsp;&nbsp; <br> <i><b>Preprint</b></i>, 2023.
				</font>
				<br>
				<div class="bu" id="2" style="display: inline-block; margin-top:0%">
					<font size="6"><i class="fa fa-info" aria-hidden="true"></i></font>&nbsp;<img alt="Static Badge"
						src="https://img.shields.io/badge/Bib-5cb85c" style="width: 35px;">
				</div>
				&nbsp;
				<div class="au" id="2" style="display: inline-block; margin-top:0%">
					<font size="6"><i class="fa fa-flag" aria-hidden="true"></i></font>&nbsp;<img alt="Static Badge"
						src="https://img.shields.io/badge/Abstract-f9adad" style="width: 70px;">
				</div>
				&nbsp;
				<!-- <a href="https://arxiv.org/abs/2308.10252"><img alt="Static Badge"
						src="https://img.shields.io/badge/Arxiv-428BCA" style="width: 50px;"></a> -->
				<a href="https://github.com/WENGSYX/LMTuner">
					<font size="6"><i class="fa fa-github-alt" aria-hidden="true"></i></font>&nbsp;<img
						alt="Static Badge" src="https://img.shields.io/badge/Code-d9534f" style="width: 50px;">
				</a>
				&nbsp;
				<a href="https://wengsyx.github.io/LMTuner/">
					<font size="6"><i class="fa fa-home" aria-hidden="true"></i></font> <img id="2" alt="Static Badge"
						src="https://img.shields.io/badge/Homepage-009fd0" style="width: 100px;">
				</a>
				&nbsp;
				<a class="tag" href="cites/LMTuner.bib" target="_self">
					<font size="6"><i class="fa fa-download" aria-hidden="true"></i></font>&nbsp;<img id="2"
						alt="Static Badge" src="https://img.shields.io/badge/Cite-edd7be" style="width: 43px;">
				</a>
				<div class="bib2" style="display:none; width: 95%; border:1px solid #e8dada">
					<pre>
  @misc{weng2023lmtuner,
  title={LMTuner: An user-friendly and highly-integrable Training Framework for fine-tuning Large Language Models}, 
  author={Yixuan Weng and Zhiqi Wang and Huanxuan Liao and Shizhu He and Shengping Liu and Kang Liu and Jun Zhao},
  year={2023},
  eprint={2308.10252},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
  }
		</pre>
				</div>
				<div class="ab2" style="display:none; width: 95%; border:1px solid #e8dada">
					<pre>
  With the burgeoning development in the realm of large language models (LLMs), the demand for efficient incremental training tailored to
  specific industries and domains continues to increase. Currently, the predominantly employed frameworks lack modular design, it often 
  takes a lot of coding work to kickstart the training of LLM. To address this, we present "LMTuner", a highly usable, integrable, and scal-
  able system for training LLMs expeditiously and with minimal user-input. LMTuner comprises three main modules - the Interaction, Train-
  ing, and Inference Modules. We advocate that LMTuner’s usability and integrality alleviate the complexities in training large language 
  models. Remarkably, even a novice user could commence raining large language models within five minutes. Furthermore, it integrates
  DeepSpeed frameworks and supports Efficient Fine-Tuning methodologies like Low Rank Adaptation (LoRA),Quantized LoRA (QLoRA), etc., 
  enabling the training of language models scaling from 300M to a whopping 130B parameters using a single server.
		</pre>
				</div>
			</li>
			<br />
			<br />
			<li>
				<font size="4">
					<b><a href="https://link.springer.com/chapter/10.1007/978-981-99-7224-1_1">Dynamic Weighted
							Neural Bellman-Ford Network for Knowledge Graph Reasoning</a></b>
				</font>
				<font size=" 3">
					&nbsp;&nbsp; <br />
					<b class="myself">Huanxuan Liao</b>
					<font face="Arial">, Shizhu He, Yao Xu, Kang Liu, Jun Zhao</font>
					&nbsp;&nbsp; <br> Accepted to <i><b>the 8th China Conference on Knowledge Graph and Semantic
							Computing</i> (CCKS)</b>, 2023.
				</font>
				<br>
				<div class="bu" id="1" style="display: inline-block; margin-top:0%">
					<font size="6"><i class="fa fa-info" aria-hidden="true"></i></font>&nbsp;<img alt="Static Badge"
						src="https://img.shields.io/badge/Bib-5cb85c" style="width: 35px;">
				</div>
				&nbsp;
				<div class="au" id="1" style="display: inline-block; margin-top:0%">
					<font size="6"><i class="fa fa-flag" aria-hidden="true"></i></font>&nbsp;<img alt="Static Badge"
						src="https://img.shields.io/badge/Abstract-f9adad" style="width: 70px;">
				</div>
				&nbsp;
				<a class="tag" href="cites/DyNBF.bib" target="_self">
					<font size="6"><i class="fa fa-download" aria-hidden="true"></i></font>&nbsp;<img id="2"
						alt="Static Badge" src="https://img.shields.io/badge/Cite-edd7be" style="width: 43px;">
				</a>
				<!-- <a href=""><img alt="Static Badge" src="https://img.shields.io/badge/Arxiv-428BCA"
						style="width: 50px;"></a> -->
				<div class="bib1" style="display:none; width: 95%; border:1px solid #e8dada">
					<pre>
  @InProceedings{10.1007/978-981-99-7224-1_1,
  author="Liao, Huanxuan
  and He, Shizhu
  and Xu, Yao
  and Liu, Kang
  and Zhao, Jun",
  editor="Wang, Haofen
  and Han, Xianpei
  and Liu, Ming
  and Cheng, Gong
  and Liu, Yongbin
  and Zhang, Ningyu",
  title="Dynamic Weighted Neural Bellman-Ford Network for Knowledge Graph Reasoning",
  booktitle="Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence",
  year="2023",
  publisher="Springer Nature Singapore",
  address="Singapore",
  pages="3--16",
  isbn="978-981-99-7224-1"
  }												
					</pre>
				</div>
				<div class="ab1" style="display:none; width: 95%; border:1px solid #e8dada">
					<pre>
  Recent studies have shown that subgraphs of the head entity, such as related relations and neighborhoods, are helpful for Knowledge Graph
  Reasoning (KGR). However, prior studies tend to focus solelyon enhancing entity representations using related relations, with little attention 
  paid to the impact of different relations on different entities and their importance in various reasoning paths. Meanwhile, conventional Graph
  Neural Networks (GNNs) utilized for KGR consider simultaneously neighboring nodes and connected relations of the head entity but typically 
  use a standard message-passing paradigm over the entire Knowledge Graph (KG). This results in oversmoothed representations and limits 
  efficiency. To address the above-mentioned limitations of existing methods, we propose a Dynamic Weighted Neural Bellman-Ford Network 
  (DyNBF) for KGR, which utilizes relation weights generated from subgraphs to compute only the most relevant relations and entities. This 
  way, we can integrate multiple reasoning paths more flexibly to achieve better interpretable reasoning, while scaling more easily to more
  complex and larger KGs. DyNBF consists of two key modules: 1) a transformer-based relation weights generator module, which computes
  the weights of different relations on the path with a sequence-to-sequence model, and 2) an NBFNet-based logic reasoner module, which 
  obtains entity representations and conducts fact prediction with dynamic weights from the previous module. Empirical results on three stand-
  ard KGR datasets demonstratethat the proposed approach can generate explainable reasoning paths and obtain competitive performance.
			</pre>
				</div>
			</li>
		</ul>
	</div>
	<br />

	<!-- <h2><font face="Arial" size=+3.5>Website visit statistics</font></h2>
	<hr/>
	<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=500&t=tt&d=RDwpltapRj65Q7UM5LGnBHaIr57MgblmTCDCr6fHKo0'></script> -->

	<br />
	<div id="copyright" align="right">
		<p>Copyright&copy; 2023 Huanxuan Liao(<font face="楷体">廖桓萱</font>).</p>
	</div>
</body>

</html>